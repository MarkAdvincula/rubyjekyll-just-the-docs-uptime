{"0": {
    "doc": "Install and Configuration Guide",
    "title": "Pre-Requisites",
    "content": " ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide#pre-requisites",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide#pre-requisites"
  },"1": {
    "doc": "Install and Configuration Guide",
    "title": " 01 Azure Prerequisites",
    "content": ". | Azure DevOps organisation with a paid tier Microsoft-hosted agent as the initial terraform may exceed the free tier time limit | Azure DevOps Terraform and File Creator Extensions | Azure AD account with access rights to Azure DevOps and rights to configure a Service Principle with Contribute Permission on Subscription | Infrastructure: https://github.dxc.com/Uptime/terraform/tree/master/cps | GitHub Enterprise to link on AzureDevOps (Terraform, Deployment pipelines) | GitHub PAT (Personal Access Token) with rights to create a GitHub Enterprise Server service connection to https://github.dxc.com | SonarQube installed in order to test code quality for backend APIs | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide#-01-azure-prerequisites",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide#-01-azure-prerequisites"
  },"2": {
    "doc": "Install and Configuration Guide",
    "title": "02 Repositories Prerequisites",
    "content": "Frontend: . | https://github.dxc.com/Uptime/Uptime-storybook | https://github.dxc.com/Uptime/portal-web | . Backend: . | https://github.dxc.com/MWA/ms-uptime-base-api | https://github.dxc.com/MWA/ms-asset-api | https://github.dxc.com/MWA/ms-user-api | https://github.dxc.com/MWA/ms-order-api | https://github.dxc.com/MWA/ms-incident-api | https://github.dxc.com/MWA/ms-shipping-api | https://github.dxc.com/MWA/ms-knowledge-api | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide#02-repositories-prerequisites",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide#02-repositories-prerequisites"
  },"3": {
    "doc": "Install and Configuration Guide",
    "title": " 03 OKTA Prerequisites",
    "content": ". | Frontend deployed in Azure DevOps pipeline | Make sure that Client ID, and base_url are already available. Client ID, and base_url should be provided once an OKTA app is created. These will be used as a configuration in one of the releases. | Logo file is obtained, stored in Okta system, and URL to logo is known. | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide#-03-okta-prerequisites",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide#-03-okta-prerequisites"
  },"4": {
    "doc": "Install and Configuration Guide",
    "title": " 04 ServiceNow Prerequisites ",
    "content": ". | Existing working ServiceNow instance | ServiceNow Password | ServiceNow URL | ServiceNow USER | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide#-04-servicenow-prerequisites-",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide#-04-servicenow-prerequisites-"
  },"5": {
    "doc": "Install and Configuration Guide",
    "title": " 06 Boomi Prerequisites ",
    "content": ". | Boomi credentials | Boomi URL | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide#-06-boomi-prerequisites-",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide#-06-boomi-prerequisites-"
  },"6": {
    "doc": "Install and Configuration Guide",
    "title": " 07 ASD Chat Prerequisites ",
    "content": ". | Deployed azure webapp for ASD CCL and edit config in here https://github.dxc.com/ModernWorkplace/FASD_Connect_Chat/blob/master/BotConnector/Configuration.json to point the correct ServiceNow | . Please refer to this document for UPtime installation prerequisites: . Pre-Requisites . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide#-07-asd-chat-prerequisites-",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide#-07-asd-chat-prerequisites-"
  },"7": {
    "doc": "Install and Configuration Guide",
    "title": "Install and Configuration Guide",
    "content": " ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide"
  },"8": {
    "doc": "Azure DevOps",
    "title": "Introduction to Components",
    "content": "This documentation covers the definition of components in Azure DevOps existing in Showcase. Please refer to documents Deployment Steps to start working on a new Pipelines. | Build Pipelines | Release Pipelines | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#introduction-to-components",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#introduction-to-components"
  },"9": {
    "doc": "Azure DevOps",
    "title": "Build Pipelines",
    "content": ". | This shows the Pipelines page where the user can view the Pipeline builds. Pipelines automatically builds and tests code projects in a repository to make them available. This tests and builds the code to make it ready for release/deployment. | In this section, Recently run pipelines can be viewed across the page. Pipelines below as can be seen, shows the: 2.1. Pipeline name 2.2. Last commit 2.3. User published/updated the pipeline 2.4. Branch 2.5. Last run date . | Clicking on a certain Pipeline name will show the recent builds ran in that pipeline. | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#build-pipelines",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#build-pipelines"
  },"10": {
    "doc": "Azure DevOps",
    "title": "Releases Pipelines",
    "content": ". | List shows the existing Release Pipelines. Release Pipelines are the next step of the Build Pipelines as discussed before this topic. | This will let you manually create a new release pipeline, or in this case for Uptime, we imported a release pipeline where the assets are already indicated, which only needs a slight modification. | Releases section shows the releases deployed. The green boxes you can see that are under the Stages column shows the stages that have been deployed. White boxes that has no checks means in that release, those have not been included for that release. As you can see in the Release-35, we only deployed a release for the frontend codebase . | Clicking on Edit will then allow to modify the Release, to prepare for the new release. | Clicking one of the Artifacts will allow you which version to pick before deploying that release pipeline. Note that this will change the artifact which will reflect all stages and steps related to it. | Clicking on Create Release will allow you to select a stage where you can trigger it manually or automatically, this will also allow you to select a version of the Artifacts loaded in that Release. | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#releases-pipelines",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#releases-pipelines"
  },"11": {
    "doc": "Azure DevOps",
    "title": "Azure DevOps Release Pipeline",
    "content": " ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#azure-devops-release-pipeline",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#azure-devops-release-pipeline"
  },"12": {
    "doc": "Azure DevOps",
    "title": "Azure Prerequisites",
    "content": ". | Azure DevOps organisation with a paid tier Microsoft-hosted agent as the initial terraform may exceed the free tier time limit | Azure DevOps Terraform and File Creator Extensions | Azure AD account with access rights to Azure DevOps and rights to configure a Service Principle with Contribute Permission on Subscription (Request for Service Principle) &lt; get the Azure Owner to setup the Service Connection directly to the Subscription used for the Terraform depolyment &gt; | Infrastructure: https://github.dxc.com/Uptime/terraform/tree/master/cps | GitHub Enterprise to link on AzureDevOps (Terraform, Deployment pipelines) | GitHub PAT (Personal Access Token) with rights to create a GitHub Enterprise Server service connection to https://github.dxc.com | SonarQube installed in order to test code quality for backend APIs | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#azure-prerequisites",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#azure-prerequisites"
  },"13": {
    "doc": "Azure DevOps",
    "title": "Deployment steps breakdown",
    "content": " ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#deployment-steps-breakdown",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#deployment-steps-breakdown"
  },"14": {
    "doc": "Azure DevOps",
    "title": "Setting up Terraform pipeline",
    "content": ". | Importing/Forking project for repositories Github source code: . https://github.dxc.com/Uptime/terraform/tree/master/cps . | Creating a Pipeline / Connecting your Github to Azure DevOps . NOTE: If you don’t have Github Organization yet, you can follow this guide Deployment Best Practices . | Go to Pipelines, and click New Pipeline | Click new connection | Enter your PAT, and Enterprise URL (ex. https://github.dxc.com) | Select All Repositories from the dropdown then select your Github Organization/repository | Click “Starter Pipeline” then click Save and Run | . If an error occurs about SonarQube, edit the YAML file and remove the SonarQube block if SonarQube is not present in current ADO instance. Select the version then click ‘Run’ button on the upper right of the page. | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#setting-up-terraform-pipeline",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#setting-up-terraform-pipeline"
  },"15": {
    "doc": "Azure DevOps",
    "title": "Creating Release Pipeline",
    "content": "For this steps, we will be importing a preset file that will add artifacts, and stages. For more information on creating from scratch, you can look up at: ‘link here’ . | Go to Releases &gt; click New &gt; Import release pipeline . | It will be looking for the Artifact that came from the template release pipeline we imported, in this case, we should remove the current artifact. Under Artifacts, click _Uptime.terraform, then click Delete. | Click ‘+ Add’ beside Artifacts, and select your Source on the right sidebar that appears, then click Add. The remaining 2 options will be autofilled once Source is selected . | Click on ‘qa’ from Stages, and rename it. You can now close the side window . | Click on “1 job, 7 tasks” under Stages . | You will be able to see 7 tasks, which are 3 File Creators, and Terraform tasks . | An error will appear on some tasks, which could be under Agent Job, and File Creators. In this case, we will install extensions that would be used for these type of tasks. Link: https://dev.azure.com/WMShowCase/_redirect?target=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3Deliostruyf.build-task%26targetId%3Da58beef4-4e5e-488a-b5e2-3d2b9731a95e . | Once done, replace the tasks’ directory name using the build pipeline path, you can also view the folder by clicking the 3 dots beside the text-field (ex. $(System.DefaultWorkingDirectory)/_Uptime-DDS.terraform-1/provision/cps/locals.tf) . | Terraform had a breaking change on the latest version, due to this, we must change the 3rd File Creator’s contents by switching the version to “2.93.1” . | Next, we will clear out ‘Agent Job’ error: . 10.1. Click ‘Agent Job’ . 10.2. On the right pane, select ‘Agent pool’ dropdown . 10.3. Select your Hosted, in our case ‘Azure Pipelines’ . 10.4. Select from the dropdown ‘Agent Specification’ &gt; latest Ubuntu version . 10.5. Once done, rename your Pipeline, on the top portion beside ‘All Pipelines &gt; provision - Copy’ by just hovering and clicking to rename . | Hit ‘Save’ . | . ## IMPORTANT: Resetting the Subscription IDs from the imported pipeline template . | For the 2 Terraform: azurerm tasks: azurerm plan, azurerm apply: . | Go to Tasks | Select one of the Terraform tasks mentioned above | Under command, select init | AzureRM backend configuration section will appear | Fill out the remaining blank fields with the right values | Hit ‘Save’ | Repeat for the remaining Terraform azurerm task | . | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#creating-release-pipeline",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#creating-release-pipeline"
  },"16": {
    "doc": "Azure DevOps",
    "title": "Declaring the variables for the pipeline",
    "content": ". | Go to Releases -&gt; click Your Pipeline -&gt; click Edit . | You will be able to see your Artifacts, and Stages. Click Variables on the top selections . | Setting up Variable groups: . Setting up Variable groups for sensitive data, like secrets, passwords, etc. 3.1. Click on ‘Manage variable groups’ . 3.2. Click on ‘+ Variable Group’ . 3.3. Name your Variable Group . 3.4. Click ‘+Add’ under Variable Group . 3.5. Add these 3: . | az_tenant - [your service principle] - Found in Azure &gt; Azure Active Directory | az_username - [your service principle] - If app has been registered, go to: Azure &gt; Azure Active Directory &gt; App registrations &gt; All applications &gt; Find app to use in the deployment - seen in column ‘Application (client) ID’ | az_password - [your service principle] - If app has been registered, go to: Azure &gt; Azure Active Directory &gt; App registrations &gt; All applications &gt; Select app &gt; Certificates &amp; Secrets &gt; Secret ID . | . 3.6. Hit ‘Save’ . 3.7. Go back to Variables . 3.8. Select ‘Variable Groups’ . 3.9. Select your created/existing Variable Group created (Service Principles) . | Setting up Pipeline Variables . 4.1. Change the az_subscription using your own azure subscription id . 4.2. Change the environment name, base on what environment this gets deployed . 4.3. Key would be the folder name in azure storage that we will use to store terraform.state, in this case you can rename it as: . your-new-directory &gt;/$(env)/terraform.tfstate . 4.4. uid (unit_id) keep it empty to auto-generate unit_id, and should be populated if we are updating . UID can only contain alphanumeric characters between 3-24 characters, you can use any input - or if needed, you can generate your UID randomly using this script, can be edited by going to: 1. Edit Release 2. Click 1 Job under Stages 3. Click 7 Tasks under provision 4. Click the 2nd File Creator and enter on the first line: resource \"random_id\" \"env_uid\" { byte_length = 4 } uid = lower(random_id.env_uid.hex) . 4.5. Tier = P1V2 default used for Staging, for more details about pricing and specification, you can view it here: . Enter Excel File for the Pricing and Specifications here . 4.6. Hit ‘Save’ . | Setting up Tasks, for Terraform - linking Service Principles in Azure subscription . 5.1. Go to Releases &gt; Click your release pipeline &gt; Click Edit . 5.2. Click Tasks . 5.3. On the 3 Terraforms job: azurerm init, azurerm plan, azurerm apply - change the Azure Subscription using your Service Connection . 5.4 Click on the ‘Agent Job’, and on the Agent Pool select your current Agent Pool to use in deploying . 5.5 On the ‘Agent Specification’, select latest ubuntu-latest version . 5.6 Click on the 2nd file creator, and under File Content - declare these in the locals block under the ‘molecule_node’: . | redis_sku_name = “Premium” | redis_family = “P” | . 5.7 File Pathname should be the same with the deployed build pipeline path, the ellipsis on the left of the field value can be used and then point to the required location (path shown in image below): . 5.8 On the same file creator shown in the image on the previous step, change the version to “2.93.1”, versions above has a breaking change that will cause issues running the release pipeline. 5.9 On the same File Creator, replace the resource group name, storage account name, and container name . | Creating a new release . 6.1. Go to ‘Releases’ . 6.2. Click ‘Create Release’ on the upper right portion of the screen . 6.3. Click ‘Create’ . | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#declaring-the-variables-for-the-pipeline",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#declaring-the-variables-for-the-pipeline"
  },"17": {
    "doc": "Azure DevOps",
    "title": "After deploying, an error will occur due to restriction on permissions. Redeploy using new Agent deployed on Uptime resource group’s VM",
    "content": ". | Details and instructions can be located at here | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#after-deploying-an-error-will-occur-due-to-restriction-on-permissions-redeploy-using-new-agent-deployed-on-uptime-resource-groups-vm",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#after-deploying-an-error-will-occur-due-to-restriction-on-permissions-redeploy-using-new-agent-deployed-on-uptime-resource-groups-vm"
  },"18": {
    "doc": "Azure DevOps",
    "title": "Notes:",
    "content": "apim.azurerm_api_management.srg could take 60-120 mins in creating so a paid agent pool might be required to increase timeout . CosmosDB only has a maximum of 44 characters, if issue is present: . creating Database Account: (Name “cosmos-ms-uptime-base-api-sc2-eastus-c129bd42” / Resource Group “rg-func-ms-uptime-base-api-sc2-eastus-c129bd42”): creating/updating CosmosDB Account “cosmos-ms-uptime-base-api-sc2-eastus-c129bd42” (Resource Group “rg-func-ms-uptime-base-api-sc2-eastus-c129bd42”): documentdb.DatabaseAccountsClient#CreateOrUpdate: Failure sending request: StatusCode=400 – Original Error: Code=”BadRequest” Message=”DatabaseAccount name ‘cosmos-ms-uptime-base-api-sc2-eastus-c129bd42’ is not valid since it is less than 3 characters or more than 44 characters long.\\r\\nActivityId: afcc278f-4e6a-4ca1-afd1-3116b6d09b21, Microsoft.Azure.Documents.Common/2.14.0 change it in the Terraform repository: cps/services/uptime_ms/main.tf . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#notes",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#notes"
  },"19": {
    "doc": "Azure DevOps",
    "title": "Deployment Best Practices",
    "content": "This documentation covers the best practices in setting up your Azure for UpTime application requirements, and APIs. In this section, this will guide us in setting up: . | Github Organization | Getting Terraform code from Uptime Terraform Github source | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#deployment-best-practices",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#deployment-best-practices"
  },"20": {
    "doc": "Azure DevOps",
    "title": "Creating Github Organization",
    "content": ". | Login to your Github | Click the ‘+’ icon on the upper right corner, beside your profile icon . | Select ‘New Organization’ . | Enter your Organization account name | . REMEMBER: Take note of your Organization Name since this will be used for the variables used in Azure DevOps, and Uptime code deployment . | Add Organization members who will be working on deploying Azure | . NOTE: Creating/Forking repository will be under your Github Organization created recently . RECOMMENDED: Forking repository . | Go into https://github.dxc.com/Uptime/terraform/tree/master/cps | On the upper right corner, click the button ‘Fork’ . | Select your Organization created in this guide. | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#creating-github-organization",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#creating-github-organization"
  },"21": {
    "doc": "Azure DevOps",
    "title": "Uploading the source code repository files into your Github Org",
    "content": ". | Create your Github Repository . | Add the ‘Repository Name’, and make sure that Public is not ticked for security purposes. OPTION: You can add a Readme.md for description or markdown files can also be created later. | . | Export then Import the Uptime’s Terraform source code from the development team in your Terraform repository. | . https://github.dxc.com/Uptime/terraform/tree/master/cps . Updating the fork from remote branch . | Click ‘Fetch Upstream’, and click ‘Fetch and Merge’. This only updates the current branch. You can also check the comparisons to check any changes made from the remote vs forked branch. | . | Once done, the build pipelines on DevOps will automatically update. You can check it on Azure DevOps as well, where the related repository is in the build pipeline. | If the build goes successful, go to Releases branch and Create a release, and select the version you want to deploy. The steps can be found at Azure DevOps at section Releases, #4. | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#uploading-the-source-code-repository-files-into-your-github-org",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#uploading-the-source-code-repository-files-into-your-github-org"
  },"22": {
    "doc": "Azure DevOps",
    "title": "Update Best Practices",
    "content": " ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#update-best-practices",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#update-best-practices"
  },"23": {
    "doc": "Azure DevOps",
    "title": "Updating the fork from remote branch",
    "content": ". | Click ‘Fetch Upstream’, and click ‘Fetch and Merge’. You can also check the comparisons to check any changes made from the remote vs forked branch. Note: Fetch Upstream only updates the current branch you fetched . | Once done, the build pipelines on DevOps will automatically update. You can check it on Azure DevOps as well, where the related repository is in the build pipeline. | If the build goes successful, go to Releases branch and Create a release, and select the version you want to deploy. The steps can be found at Azure DevOps at section Releases, #4. | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps#updating-the-fork-from-remote-branch-1",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps#updating-the-fork-from-remote-branch-1"
  },"24": {
    "doc": "Azure DevOps",
    "title": "Azure DevOps",
    "content": ". | Introduction to Components . | Build Pipelines | Releases Pipelines | . | Azure DevOps Release Pipeline . | Azure Prerequisites | . | Deployment steps breakdown . | Setting up Terraform pipeline | Creating Release Pipeline | Declaring the variables for the pipeline | After deploying, an error will occur due to restriction on permissions. Redeploy using new Agent deployed on Uptime resource group’s VM | Notes: | . | Deployment Best Practices . | Creating Github Organization . | RECOMMENDED: Forking repository | . | Uploading the source code repository files into your Github Org . | Updating the fork from remote branch | . | . | Update Best Practices . | Updating the fork from remote branch | . | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/01%20Azure%20DevOps",
    "relUrl": "/docs/Delivery-kit/Install and Configuration Guide/01 Azure DevOps"
  },"25": {
    "doc": "UPtime Portal",
    "title": "UPtime Install Process",
    "content": " ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#uptime-install-process",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#uptime-install-process"
  },"26": {
    "doc": "UPtime Portal",
    "title": "Azure Prerequisites",
    "content": "Frontend: . | https://github.dxc.com/Uptime/Uptime-storybook | https://github.dxc.com/Uptime/portal-web | . Backend: . | https://github.dxc.com/MWA/ms-uptime-base-api | https://github.dxc.com/MWA/ms-asset-api | https://github.dxc.com/MWA/ms-user-api | https://github.dxc.com/MWA/ms-order-api | https://github.dxc.com/MWA/ms-incident-api | https://github.dxc.com/MWA/ms-shipping-api | https://github.dxc.com/MWA/ms-knowledge-api | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#azure-prerequisites",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#azure-prerequisites"
  },"27": {
    "doc": "UPtime Portal",
    "title": "Creating a Pipeline for the source code",
    "content": "Notes: . | If Forking is currently disabled, please create your own repository having the api name. ex: “https://github.dxc.com/your-git-org-name-here/ms-uptime-base-api” . | . | Go to either Frontend or Backend repositories, depends on where you’re currently at | Export | Push on your repository | . | (RECOMMENDED) If Forking is enabled, you can fork the repository on your own organization as per - mentioned in the Prerequisites. Please fork the repositories for both backend and frontend to be used in the pipeline. | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#creating-a-pipeline-for-the-source-code",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#creating-a-pipeline-for-the-source-code"
  },"28": {
    "doc": "UPtime Portal",
    "title": "Creating a build pipeline for each artifacts",
    "content": ". | Creating a Pipeline / Connecting your Github to Azure DevOps | . | Go to Pipelines, and click New Pipeline . | Select GitHub Enterprise Server . | Click new connection . | Enter your Personal Access Token (PAT), and Enterprise URL (ex. https://github.dxc.com) then click Create . | Select All Repositories from the dropdown then select your Github path, should be &lt; Organization &gt;/&lt; repository &gt; . | Apply for all Front-end, and backend repositories . | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#creating-a-build-pipeline-for-each-artifacts",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#creating-a-build-pipeline-for-each-artifacts"
  },"29": {
    "doc": "UPtime Portal",
    "title": "Add a new Service Connection for Docker/Container",
    "content": ". | Docker Registry Service Password can be found by going to Azure -&gt; cruptime{env}{uid} -&gt; Access Keys &gt; password | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#add-a-new-service-connection-for-dockercontainer",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#add-a-new-service-connection-for-dockercontainer"
  },"30": {
    "doc": "UPtime Portal",
    "title": "Importing presets",
    "content": "Note . | Importing a json file will include all the applications, settings and configurations for tasks that will be used in both Front-end and Back-end codes: . | To quickly modify, replace existing items with the proper values, you can use the find function on a text editor you’re using by finding this values: . | {uid} - uid generated from deploying the provision using Terraform | {env} - env used from provision | {directory} - directory of the artifact/build pipeline location (ex. _UptimeforShowcase) | {az_subscription} - Subscription ID | . | . Get showcase backend release pipeline template deployment json here . | After importing, make sure to remove all the artifacts | . | Reimport the artifacts by clicking on the ‘+’ button beside ‘Artifacts’, and reimport every pipeline created mentioned in the first section “Creating a pipeline for each artifacts”. | Click on ‘1 job 7 tasks’ in ‘frontend’, under Stages . | On ‘Agent Job’, select in ‘Agent pool’ your Azure Pipeline . | On ‘Agent Specification’, select the ‘latest Ubuntu version’ for tasks that has ‘Container’ and the ‘Front-end’ part. For backends that has the ‘PowerShell script’ tasks, please select ‘windows-2019’. | Under ‘Agent Job’, check each tasks and make sure that Source Folder, Target Folder, File Path are all located in your system’s working directory. ex: . | . Current path: $(System.DefaultWorkingDirectory)/_UptimeforShowcase.uptime-storybook/uptime-storybook . Replace to: $(System.DefaultWorkingDirectory)/_&lt;Your-git-org-here&gt;.uptime-storybook/uptime-storybook . | Rename the CosmosDB path with your current CosmosDB on the backend artifacts: . | In the Variables tab, make sure your variables below are not modified: . | az_subscription - can be found in your service connection | REACT_APP_OCP_APIM_SUBSCRIPTION_KEY can be found in your service connection | uid can be found on the first pipeline/release setup, which is the provision we created in (01 Azure - Provision/02 Deployment Steps) | . | . | Some Variables configurations: | . | For most backend that has the ‘API Management - Create/Update API’, add: Unlimited uptime | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#importing-presets",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#importing-presets"
  },"31": {
    "doc": "UPtime Portal",
    "title": "Re-deploying latest releases (if issues exist)",
    "content": ". | Go to Release, and click your codes pipeline then click on ‘Edit’ . | For backend . | ms-asset | ms-order | ms-knowledge | ms-incident | ms-uptime | . | . Apply these steps below to the apis mentioned above. We will be working on the ms-asset: . a. Click on ms-asset ‘3 jobs, 11 tasks’ b. Applicable for the tasks below, on the first Agent job: . | Powershell Script | Command Line Script | npm install | . Click on each, and then click on ‘Advanced’ . c. Click on the three dots, and locate the api we are currently configurin - at this moment ‘ms-asset-api’ . d. Locate on the folders the ‘database’ folder, found at /azure/database/latest_release/ e. Select the earliest release (ex. R2 21.10.6) . f. Apply the same steps above for the ‘npm install’ task . g. Click on Create Release on the upper right part of the screen . h. Repeat the same creation of releases in order, going all the way up to the latest release. Ex: . | Release 1: R2 21.10.6 | Release 2: R2 21.11.1 | Release 2: R2 21.11.1a | . i. This is what it would look like once done . Note that some releases are failed or marked as ‘x’. You can cancel the deployment once the first Agent Job is done and it would still apply the changes . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#re-deploying-latest-releases-if-issues-exist",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#re-deploying-latest-releases-if-issues-exist"
  },"32": {
    "doc": "UPtime Portal",
    "title": "Client Customization Guide",
    "content": " ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#client-customization-guide",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#client-customization-guide"
  },"33": {
    "doc": "UPtime Portal",
    "title": "Overview",
    "content": "The Overview section holds the high-level configurable areas of the Uptime. The customizable will list all the current possible configurable aspects of Uptime and include also the components that are non-configurable dated, and currently on the roadmap. In this document will also include the guide on applying the current available customizable parts of Uptime.&lt;/i&gt; . This document focuses on the possible areas that can and will be customized as part of the portal rollout for customers. Please take note of the release information within each of the links referenced below for proper guidance. The configurations that can be customized are different depending on agreement with the customer and overall environment state. These are stored as part of the Azure space within the Cosmos DB. The procedures for applying these customizations are also covered in respective sections of the Installation and Configuration Guide (e.g. API, variables, CosmosDB, etc…) . Current state . All changes to the portal’s configuration described below as BRANDING &amp; NON-BRANDING will result in a change in the base code. Proposed changes go through an approval process which flows through 2 teams - UI Design &amp; the Developer Teams (Front End &amp; Back End), details listed below: . | A proposed change is submitted to the appropriate team for approval . | BRANDING: UI Design and Front End Developer Team . | Each team will work through a User Story in Jira to work on the proposed changes (Design &amp; Implementation). This process is outlined here. You can adjust the version history if you need to check the latest one. Once actions are completed, code changes are committed into GitHub | . | NON-BRANDING: Back End Developer Team . | Changes to the code are committed through a release pipeline into the Azure environment, similar to branding they are worked through User Stories in Jira for proper tracking | . | . | . NOTE: There will most likely be changes in this approach, this space will be updated once plans are finalized . Branding . The below information refers to the front-end (UI design) specifications that can be configured/customized if so desired. You can find all the current designs here, all changes to conventions, workflow, etc. will be reflected at this location accordingly. (Note: Some of the items listed below are still being worked on by the dev team to be available for customization) . | Login page (Authentication) &lt; click here for the instruction guide &gt; . | Authentication (like Okta) can be indicated on the Azure DevOps | . | Landing page &lt; click here for the instruction guide &gt; . | Customer Logo and Favicon. | Customer Portal Color Theme | Customer Font Size, Style, Color, Font Name &lt; Refer here for developers document &gt; | . | Limited Access Landing Page . | This can also be considered under the Pilot Mode currently which can be found here &lt; click here for the instruction guide &gt; This is currently under development. | ITSM Portal URL - Added in the list for to do | . | User profile (Photo) . | User profile image file can be located in Azure Active Directory which is also linked in O365. | Switching from a different source is considered, and will be on to-do list in development stage | . | Survey (Qualtrics) . | Removing the Feedback button by removing Qualtrics &lt; click here for the instruction guide &gt; | . | . Potential new configurations . Overall Potential new configurations can be found here, included are: . | In progress . | Landing Page | ITSM Portal URL | User Profile (Photo) | Language | . | To do . | Limited Access Landing Page | User Profile details in other sources (ex: Azure AD, Workday, etc..) | Language | Resource Limitations | . | . Current resources used for design, branding and general portal UI can be found here. Resource categories defined as well (Approved, Agile, Design, etc.) . Non-branding . The below configuration pages are located in this main page and it is advised to check this space as more configuration pages are added. At its current state, the specifics that can be configured and can be taken : . | Policies for PC Lifecycle/Refresh (Asset) Configurations are not yet applicable. Connect with the Boomi Team to have this configured which are the: . | Item availability or stock | User qualification | Refresh status | Flags | . | Incident Lifecycle &lt; click here for the instruction guide &gt; . | Incident Filters | Incident State &lt;&gt; Filter Mappings . | Incident State Mappings | Incident Resolved State | . | Incident Resolved Close Code | Incident Resolved Close Notes | Incident Resolved Comment . | Incident Reopen State | Incident Reopen Comment | . | Incident Action Rules | . | Knowledge documentation specifications &lt; click here for the instruction guide &gt; . | Knowledge Template URL | Knowledge Annoucement Conditon | Knowledge Content Text Limit | Knowledge Annoucement Encoded Query | Knowledge Featured Encoded Query | Knowledge News Encoded Query | Knowledge Top View By Category Encoded Query | . | Policies for item procurement (Order) &lt; click here for the instruction guide &gt; . | Request Item State &lt;&gt; Filter Mappings | Request Item Filter Mappings . | Request Item State Mappings | Request Item Action Rules | . | . | Location (Shipping) &lt; click here for the instruction guide &gt; . | Country . | countryMap | . | Country specifications (State, City, Region) . | countryAddressFields | . | Shipping provider . | providerMap | . | . | Other preferences (UPtime-based) . | Password preferences (length, expiry, reminder, link) . | Attachment limitations (file extension, size) . | . | . Resource limitations . | Restrictions on the file type and size of resource files such as company logo will be documented as DXC encounters specific incompatibilities. At the current time, no restrictions are known, apart from using reasonably-sized logos that fit within the visual framework of the UPtime page headers. | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#overview",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#overview"
  },"34": {
    "doc": "UPtime Portal",
    "title": "Apply Customization instructions",
    "content": "Connecting to CosmosDB in Azure will block your IP Address due to IP addresses not registered in the firewall setting . In order to access the CosmosDB Data Explorer, do the following steps: 1. In the CosmosDB of the current API in Azure, locate Settings section on the side panel 2. Click ‘Firewall and virtual networks’ 3. Click ‘Add my current IP (192.168.0.1)’ . Branding . Login Page . In authentication, please make sure that the prerequsities are already available such as Base URL, ClientID, Logo . | Authentication . | The authentication and the redirect can be configured in the Azure DevOps Front-end section . | Log-on to your Azure DevOps and go to the front-end release pipeline | Click on Tasks, and locate the 3rd File Creator under the CMD script | Scroll down until you see the 3 sections which shows . | REACT_APP_OKTA_BASE_URL= ####### | REACT_APP_OKTA_CLIENTID= ########### | REACT_APP_OKTA_LOGO= ############# | . | . | . | . Landing Page . | Customer Logo and Favicon . | Log in to Azure DevOps | Go to Release pipeline | Select ms-uptimebase-api | Click Edit &gt; Task | Create a new task (Azure Blob) | Refer here for the configuration of the new task and CosmosDB for the API. | This link here shows other variables that can be configured. (Draft status) | . | Double check that AZURE_STORAGE env variable is added in func-uptime-base with the value shown below. | . | . Limited Access Landing Page . Database Configurations such as CosmosDB requires a different level of access which authenticates directly to the host (like SSH) in local connection settings . | Limited Access Landing Page: As of now, this can be currently done via Pilot Mode. Reference link here Note that if the value is blank or empty, users who has assigned and accessed SNOW (DXCI) can use Uptime portal. | Locate the ms-user-api resource group in Azure | Apply the changes: . | { “type”: “PILOT_USER_GROUP_NAME”, “value”: “Uptime Pilot Users”, “id”: “3284c5cf-c5c3-4ad4-b765-3ab2be785176” } | . | . | . Non- Branding . Database Configurations such as CosmosDB requires a different level of access which authenticates directly to the host (like SSH) in local connection settings. Once able to access the CosmosDB, go to the Resource Group of the API to configure (ex: rg-func-ms-user-api-ph3-ph-id89231 ) . Incident Lifecycle . This can be done via configuration in CosmosDB . | Configuration are currently listed under the link here | Environment Variables as indicated from the link provided above, can also be configured such as CUSTOM_INTEGRATION (Which is indicating if REST API is used or false if Table API will be used), SNOW URL,CosmosDB | . Knowledge Lifecycle . This can be done via configuration in CosmosDB . | Configuration are currently listed under the link here | Environment Variables as indicated from the link provided above, can also be configured such as CUSTOM_INTEGRATION (Which is indicating if REST API is used or false if Table API will be used), SNOW URL,CosmosDB | . Policies for item procument (Order) . This can be done via configuration in CosmosDB . | Configuration are currently listed under the link here | Environment Variables as indicated from the link provided above, can also be configured such as CUSTOM_INTEGRATION (Which is indicating if REST API is used or false if Table API will be used), SNOW URL,CosmosDB | . Shipping . This can be done via configuration in CosmosDB . | Configuration are currently listed under the link here | Environment Variables should also be configured if there are new providers with parameters such as URL, SECRET_KEY, PASSWORD, ACCOUNT NUMBER, METER_NUMBER . | This can be done by going to Azure DevOps | Go to the release pipeline of the environment to be configured | Edit Pipeline | Go to Variables and add/edit the parameters as needed. | . | . Qualtrics . Removing Code Snippet values from CosmosoDB in uptime-base api . | Configuration are currently listed under the link here | The values as indicated on the link above, shall have blank values - example: \"id\": \"\", \"type\": \"\", \"value\": [ { \"qualtricsInstanceID\": \"\", \"snippetValue\": \"\" } ] } . | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#apply-customization-instructions",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#apply-customization-instructions"
  },"35": {
    "doc": "UPtime Portal",
    "title": "Integrating UPtime with Teams App",
    "content": "This document contains the instructions on how to integrate UPtime with a customer’s Microsoft Teams app. The process will be divided in to two separate tasks by the Development team and the Customer. | Development team’s task - The team will generate a Manifest.json for UPtime that needs to be sent to the customer. Refer below on how to generate the manifest: | . ​ 1.1 Open Microsoft Teams app . ​ 1.2 Click on the Ellipsis &gt; App Studio to install. ​ . ​ 1.3 Click Create a new app . ​ 1.4 Enter the application (UPtime) details. ​ 1.5 Click Tabs &gt; Add under Add a Personal Tab . ​ 1.6 Input the tab details then click Save. ​ . ​ 1.7 Go to Finish section then click Test and distribute &gt; Download . ​ 1.8 A .zip file will be generated that includes the Manifest.json file along with two other files. The package will be sent to the Customer. | The Customer’s Microsoft Teams admin will push the package to their company store. | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#integrating-uptime-with-teams-app",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#integrating-uptime-with-teams-app"
  },"36": {
    "doc": "UPtime Portal",
    "title": "User Profile Picture configure via AAD",
    "content": "This document will guide to configure Azure Active Directory to access the user profile picture. This is required in the customer’s Azure AD Tenant . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#user-profile-picture-configure-via-aad",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#user-profile-picture-configure-via-aad"
  },"37": {
    "doc": "UPtime Portal",
    "title": "Instructions",
    "content": "*NOTE IF YOU ALREADY HAVE AAD APP REGISTERED: the steps under creating/registering aad are required for creating the service principal, if the application has been already created, you can skip the steps and confirm that . | Who can use this application or access this API? - Accounts in this organizational directory only (Single-tenant) Click here to go to step 1 | API Permissions has MS-Graph which has - User.Read.All Click here to go to step 3 | API permissions has - Grant admin consent for &lt; single-tenant &gt; Click here to go to step 4 | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#instructions",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#instructions"
  },"38": {
    "doc": "UPtime Portal",
    "title": "Creating/Registering an application and granting API access permission",
    "content": ". | Register an application in Azure AD . | Create a new client secret . Copy client secret value . | Grant API Permissions . | Grant Admin Consent . | . Provide Tenant ID, Client ID and Client Secret to the deployment team . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#creatingregistering-an-application-and-granting-api-access-permission",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#creatingregistering-an-application-and-granting-api-access-permission"
  },"39": {
    "doc": "UPtime Portal",
    "title": "User Profile Picture AAD Access",
    "content": "This document will guide to configure Azure Active Directory to access the user profile picture. This is required in the customer’s Azure AD Tenant . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#user-profile-picture-aad-access",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#user-profile-picture-aad-access"
  },"40": {
    "doc": "UPtime Portal",
    "title": "Instructions",
    "content": "*NOTE IF YOU ALREADY HAVE AAD APP REGISTERED: the steps under creating/registering aad are required for creating the service principal, if the application has been already created, you can skip the steps and confirm that . | Who can use this application or access this API? - Accounts in this organizational directory only (Single-tenant) Click here to go to step 1 | API Permissions has MS-Graph which has - User.Read.All Click here to go to step 3 | API permissions has - Grant admin consent for &lt; single-tenant &gt; Click here to go to step 4 | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#instructions-1",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#instructions-1"
  },"41": {
    "doc": "UPtime Portal",
    "title": "Creating/Registering an application and granting API access permission",
    "content": ". | Register an application in Azure AD . | Create a new client secret . Copy client secret value . | Grant API Permissions . | Grant Admin Consent . | . Provide Tenant ID, Client ID and Client Secret to the deployment team . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#creatingregistering-an-application-and-granting-api-access-permission-1",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html#creatingregistering-an-application-and-granting-api-access-permission-1"
  },"42": {
    "doc": "UPtime Portal",
    "title": "UPtime Portal",
    "content": ". | UPtime Install Process . | Azure Prerequisites | Creating a Pipeline for the source code | Creating a build pipeline for each artifacts | Add a new Service Connection for Docker/Container | Importing presets . | Note | . | Re-deploying latest releases (if issues exist) | . | Client Customization Guide . | Overview . | Current state | Branding | Potential new configurations | Non-branding . | Resource limitations | . | . | Apply Customization instructions . | Branding . | Login Page | Landing Page | Limited Access Landing Page | . | Non- Branding . | Incident Lifecycle | Knowledge Lifecycle | Policies for item procument (Order) | Shipping | Qualtrics | . | . | . | Integrating UPtime with Teams App | User Profile Picture configure via AAD . | Instructions | Creating/Registering an application and granting API access permission | User Profile Picture AAD Access | Instructions | Creating/Registering an application and granting API access permission | . | . ",
    "url": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html",
    "relUrl": "/docs/Delivery-kit/Install%20and%20Configuration%20Guide/02%20UPtime%20Portal/01%20Install%20Process.html"
  },"43": {
    "doc": "CICD Pipelines",
    "title": "General Application CI/CD Overview",
    "content": "This document is being provided as a general reference and is not directly applicable to UPtime deployment and configuration procedures. ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#general-application-cicd-overview",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#general-application-cicd-overview"
  },"44": {
    "doc": "CICD Pipelines",
    "title": "How we manage source code for release",
    "content": " ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#how-we-manage-source-code-for-release",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#how-we-manage-source-code-for-release"
  },"45": {
    "doc": "CICD Pipelines",
    "title": "Github Work Flow",
    "content": ". | https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow Develop and Master Branches . | Instead of a single master branch, this workflow uses two branches to record the history of the project. The master branch stores the official release history, and the develop branch serves as an integration branch for features. It’s also convenient to tag all commits in the master branch with a version number. | . Feature Branches . | Each new feature should reside in its own branch, which can be pushed to the central repository for backup/collaboration. But, instead of branching off of master, feature branches use develop as their parent branch. When a feature is complete, it gets merged back into develop. Features should never interact directly with master. | We suggest we should give the feature branch as JIRA ticket number, it will help us to manage them in the future . | When you’re done with the development work on the feature, the next step is to merge the feature_branch into develop. | . Release Branches . | Once develop has acquired enough features for a release (or a predetermined release date is approaching), you fork a release branch off of develop. Creating this branch starts the next release cycle, so no new features can be added after this point—only bug fixes, documentation generation, and other release-oriented tasks should go in this branch. Once it’s ready to ship, the release branch gets merged into master and tagged with a version number. In addition, it should be merged back into develop, which may have progressed since the release was initiated. | Using a dedicated branch to prepare releases makes it possible for one team to polish the current release while another team continues working on features for the next release. It also creates well-defined phases of development (e.g., it’s easy to say, “This week we’re preparing for version 4.0,” and to actually see it in the structure of the repository). | . Hotfix Branches . | Maintenance or “hotfix” branches are used to quickly patch production releases. Hotfix branches are a lot like release branches and feature branches except they’re based on master instead of develop. This is the only branch that should fork directly off of master. As soon as the fix is complete, it should be merged into both master and develop (or the current release branch), and master should be tagged with an updated version number. | . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#github-work-flow",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#github-work-flow"
  },"46": {
    "doc": "CICD Pipelines",
    "title": "Azure DevOps Variables and Security",
    "content": "Variables give you a convenient way to get key bits of data into various parts of the pipeline. The most common use of variables is to define a value that you can then use in your pipeline. All variables are stored as strings and are mutable. The value of a variable can change from run to run or job to job of your pipeline. When you define the same variable in multiple places with the same name, the most locally scoped variable wins. So, a variable defined at the job level can override a variable set at the stage level. A variable defined at the stage level will override a variable set at the pipeline root level. A variable set in the pipeline root level will override a variable set in the Pipeline settings UI. Variables are different from runtime parameters, which are typed and available during template parsing. Use a variable group to store values that you want to control and make available across multiple pipelines. You can also use variable groups to store secrets and other values that might need to be passed into a YAML pipeline. Variable groups are defined and managed in the Library page under Pipelines. More information: https://docs.microsoft.com/en-us/azure/devops/pipelines/library/variable-groups?view=azure-devops&amp;tabs=classic . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#azure-devops-variables-and-security",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#azure-devops-variables-and-security"
  },"47": {
    "doc": "CICD Pipelines",
    "title": "Variable scopes",
    "content": "In the YAML file, you can set a variable at various scopes: . | At the root level, to make it available to all jobs in the pipeline. | At the stage level, to make it available only to a specific stage. | At the job level, to make it available only to a specific job. When a variable is defined at the top of a YAML, it will be available to all jobs and stages in the pipeline and is a global variable. Global variables defined in a YAML are not visible in the pipeline settings UI. | . Variables at the job level override variables at the root and stage level. Variables at the stage level override variables at the root level. ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#variable-scopes",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#variable-scopes"
  },"48": {
    "doc": "CICD Pipelines",
    "title": "Access variables through the environment",
    "content": "Notice that variables are also made available to scripts through environment variables. The syntax for using these environment variables depends on the scripting language. The name is upper-cased, and the . is replaced with the _. This is automatically inserted into the process environment. Here are some examples: . | Batch script: %VARIABLE_NAME% | PowerShell script: $env:VARIABLE_NAME | Bash script: $VARIABLE_NAME | . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#access-variables-through-the-environment",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#access-variables-through-the-environment"
  },"49": {
    "doc": "CICD Pipelines",
    "title": "Set secret variables",
    "content": "To set secrets in the web interface, follow these steps: . | Go to the Pipelines page, select the appropriate pipeline, and then select Edit. | Locate the Variables for this pipeline. | Add or update the variable. | Select the Secret lock icon to store the variable in an encrypted manner. | Save the pipeline. | Secret variables are encrypted at rest with a 2048-bit RSA key. Secrets are available on the agent for tasks and scripts to use. Be careful about who has access to alter your pipeline. | . Unlike a normal variable, they are not automatically decrypted into environment variables for scripts. You need to explicitly map secret variables. ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#set-secret-variables",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#set-secret-variables"
  },"50": {
    "doc": "CICD Pipelines",
    "title": "Share variables across pipelines",
    "content": "To share variables across multiple pipelines in your project, use the web interface. Under Library, use variable groups. More information: https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops&amp;tabs=yaml%2Cbatch . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#share-variables-across-pipelines",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#share-variables-across-pipelines"
  },"51": {
    "doc": "CICD Pipelines",
    "title": "Terraform",
    "content": "For the application we are using terraform to build and deploy the environments and components . Prerequisites . | Terraform CLI: https://www.terraform.io/downloads.html ( for development environment) | Azure Service Principle Key has Owner Permission on Subscription | Has Access Rights to access Azure DevOps | https://dev.azure.com/mwa-microservices/Microservices%20Capabilities Source Code and Build | https://github.dxc.com/MWA/provision | https://dev.azure.com/mwa-microservices/Microservices%20Capabilities/_release?_a=releases&amp;view=mine&amp;definitionId=1 | . variable \"customer_name\" { default = \"$(customer_name)\" } variable \"az_subscription\" { default = \"$(az_subscription)\" } variable \"az_username\" { default = \"$(az_username)\" } variable \"az_password\" { default = \"$(az_password)\" } variable \"az_tenant\" { default = \"$(az_tenant)\" } variable \"DOCKER_REGISTRY_SERVER_PASSWORD\" { default = \"$(DOCKER_REGISTRY_SERVER_PASSWORD)\" } variable \"DOCKER_REGISTRY_SERVER_URL\" { default = \"$(DOCKER_REGISTRY_SERVER_URL)\" } variable \"DOCKER_REGISTRY_SERVER_USERNAME\" { default = \"$(DOCKER_REGISTRY_SERVER_USERNAME)\" } variable \"frontend_image\" { default = \"$(frontend_image)\" } variable \"backend_image\" { default = \"$(backend_image)\" } variable \"itsm_image\" { default = \"$(itsm_image)\" } variable \"itsm_servicenow_image\" { default = \"$(itsm_servicenow_image)\" } variable \"app_database_image\" { default = \"$(app_database_image)\" } variable \"notification_image\" { default = \"$(notification_image)\" } variable \"apim_sku_name\" { default = \"$(apim_sku_name)\" } variable \"location\" { default = \"$(location)\" } variable \"PDXC_API\" { default = \"$(PDXC_API)\" } variable \"SNOW_PW\" { default = \"$(SNOW_PW)\" } variable \"SNOW_URL\" { default = \"$(SNOW_URL)\" } variable \"SNOW_USER\" { default = \"$(SNOW_USER)\" } variable \"keyvault_name\" { default = \"$(keyvaultName)\" } variable \"apim_name\" { default = \"$(apim_name)\" } variable \"cdn_name\" { default = \"$(cdn_name)\" } variable \"KB_ANNOUCEMENT_ENCODED_QUERY\" { default = \"$(KB_ANNOUCEMENT_ENCODED_QUERY)\" } variable \"KB_FEATURED_ENCODED_QUERY\" { default = \"$(KB_FEATURED_ENCODED_QUERY)\" } variable \"KB_TOP_ENCODED_QUERY\" { default = \"$(KB_TOP_ENCODED_QUERY)\" } variable \"KB_ANNOUCEMENT_CONDITION\" { default = \"$(KB_ANNOUCEMENT_CONDITION)\" } variable \"FIREBASE_ADMIN_AUTH\" { default = \"$(FIREBASE_ADMIN_AUTH)\" } variable \"FIREBASE_ADMIN_ENDPOINT\" { default = \"$(FIREBASE_ADMIN_ENDPOINT)\" } variable \"KB_BASE_IDS\" { default = \"$(KB_BASE_IDS)\" } . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#terraform",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#terraform"
  },"52": {
    "doc": "CICD Pipelines",
    "title": "Deployment Patterns:",
    "content": ". | $(name)-shared-resource (resource group) . | $(name)-appservice-linux (appservice - https://azure.microsoft.com/en-us/services/app-service/) | $(name)–application-insight ( application insight - https://docs.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview) | tfsta (storage account- https://azure.microsoft.com/en-us/pricing/details/storage/) | $(name)-apim $(name)-frontend (azure front door - https://azure.microsoft.com/en-us/services/frontdoor/) | $(name)wafpolicy (WAF policy - https://docs.microsoft.com/en-us/azure/web-application-firewall/ag/policy-overview) | $(name)-microservices-apim (api management - https://azure.microsoft.com/en-us/services/api-management/) | $(name)-cosmos-db (https://azure.microsoft.com/en-us/services/cosmos-db/) | $(name)-redis-cache (https://azure.microsoft.com/en-us/services/cache/) | $(name)-srg (https://docs.microsoft.com/en-us/azure/virtual-network/network-security-groups-overview) | $(name)-vnet (https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-overview) | $(name)-keyvault (https://azure.microsoft.com/en-us/services/key-vault/) | . | $(name)-frontend (resource group) . | $(name)-frontend (webapp - https://azure.microsoft.com/en-us/services/app-service/web/) | . | $(name)-backend (resource group) . | itsm-microservice (function app - https://azure.microsoft.com/en-us/services/functions/) | itsm-servicenow-microservice (function app - https://azure.microsoft.com/en-us/services/functions/) | app-database-microservice (function app - https://azure.microsoft.com/en-us/services/functions/) | . | . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#deployment-patterns",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#deployment-patterns"
  },"53": {
    "doc": "CICD Pipelines",
    "title": "Front End CI/CD",
    "content": " ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#front-end-cicd",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#front-end-cicd"
  },"54": {
    "doc": "CICD Pipelines",
    "title": "Prerequisites",
    "content": ". | Azure Service Principle Key has Owner Permission on Subscription | Has Access Rights to access Azure DevOps | https://dev.azure.com/mwa-microservices/Microservices%20Capabilities | . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#prerequisites",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#prerequisites"
  },"55": {
    "doc": "CICD Pipelines",
    "title": "Source Code and Build",
    "content": ". | https://github.dxc.com/MWA/helix-frontend-webapp | https://dev.azure.com/mwa-microservices/Microservices%20Capabilities/_build?definitionId=4 | . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#source-code-and-build",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#source-code-and-build"
  },"56": {
    "doc": "CICD Pipelines",
    "title": "Build Pipeline:",
    "content": "For the latest version you can find in here https://github.dxc.com/MWA/helix-frontend-webapp/blob/develop/azure-pipelines.yml . - stage: Vulnerability displayName: Scan vulnerability application jobs: - job: Npm_Vulnerability displayName: Npm Vulnerability steps: - task: Npm@1 displayName: npm install inputs: command: 'install' workingDir: 'azure/src' - task: CmdLine@2 displayName: npm audit inputs: script: | sudo npm install -g retire --unsafe-perm=true --allow-root sudo npm install -g npm-audit-html --unsafe-perm=true --allow-root npm audit --json | npm-audit-html ls workingDirectory: 'azure/src' - task: CopyFiles@2 displayName: 'Copy Files to: Copy Vulnerability Report' inputs: SourceFolder: './azure/src' Contents: | npm-audit.html !node_modules/** TargetFolder: '$(Build.ArtifactStagingDirectory)' OverWrite: true - task: PublishBuildArtifacts@1 inputs: PathtoPublish: '$(Build.ArtifactStagingDirectory)' ArtifactName: 'vulnerability-report' publishLocation: 'Container' - stage: Publish displayName: Publish Artifacts jobs: - job: publish displayName: Publish steps: - task: Docker@2 inputs: containerRegistry: 'mwamicroservicesdev' repository: 'mwa-microservice/build/helix/helix-frontend' command: 'buildAndPush' Dockerfile: 'azure/src/Dockerfile' tags: '$(Build.SourceBranchName).$(Build.BuildId)' - task: CopyFiles@2 displayName: 'Copy Files to: Staging Artifact' inputs: SourceFolder: ./azure TargetFolder: '$(Build.ArtifactStagingDirectory)' OverWrite: true - task: PublishBuildArtifacts@1 inputs: PathtoPublish: '$(Build.ArtifactStagingDirectory)' ArtifactName: 'uptime-frontend' publishLocation: 'Container' . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#build-pipeline",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#build-pipeline"
  },"57": {
    "doc": "CICD Pipelines",
    "title": "Configuration file",
    "content": "For some limitation in React we can’t set variables environment in azure webapp settings. We need to modify it before docker build step . | https://dev.azure.com/mwa-microservices/Microservices%20Capabilities/_release?_a=releases&amp;view=mine&amp;definitionId=8 REACT_APP_AZURE_REG=$(REACT_APP_AZURE_REG) REACT_APP_WEBSITE_NAME=$(REACT_APP_WEBSITE_NAME) REACT_APP_OCP_APIM_URL=$(REACT_APP_OCP_APIM_URL) REACT_APP_OCP_APIM_SUBSCRIPTION_KEY=$(REACT_APP_OCP_APIM_SUBSCRIPTION_KEY) REACT_APP_APPINSIGHTS_INSTRUMENTATIONKEY=$(APPINSIGHTS_INSTRUMENTATIONKEY) REACT_APP_OKTA_BASE_URL=$(REACT_APP_OKTA_BASE_URL) REACT_APP_OKTA_CLIENTID=$(REACT_APP_OKTA_CLIENTID) REACT_APP_OKTA_LOGO=$(REACT_APP_OKTA_LOGO) REACT_APP_FIREBASE_APIKEY=$(REACT_APP_FIREBASE_APIKEY) REACT_APP_FIREBASE_AUTHDOMAIN=$(REACT_APP_FIREBASE_AUTHDOMAIN) REACT_APP_FIREBASE_PROJECTID=$(REACT_APP_FIREBASE_PROJECTID) REACT_APP_FIREBASE_STORAGEBUCKET=$(REACT_APP_FIREBASE_STORAGEBUCKET) REACT_APP_FIREBASE_MESSAGINGSENDERID=$(REACT_APP_FIREBASE_MESSAGINGSENDERID) REACT_APP_FIREBASE_APPID=$(REACT_APP_FIREBASE_APPID) REACT_APP_NOTIFICATION_OCP_APIM_URL=$(REACT_APP_NOTIFICATION_OCP_APIM_URL) REACT_APP_NOTIFICATION_OCP_APIM_SUBSCRIPTION_KEY=$(REACT_APP_NOTIFICATION_OCP_APIM_SUBSCRIPTION_KEY) . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#configuration-file",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#configuration-file"
  },"58": {
    "doc": "CICD Pipelines",
    "title": "Backend CI/CD",
    "content": " ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#backend-cicd",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#backend-cicd"
  },"59": {
    "doc": "CICD Pipelines",
    "title": "ITSM CI/CD",
    "content": "Prerequisites . | Azure Service Principle Key has Owner Permission on Subscription | Has Access Rights to access Azure DevOps | https://dev.azure.com/mwa-microservices/Microservices%20Capabilities Source Code and Build . | https://github.dxc.com/MWA/ms-itsm | https://dev.azure.com/mwa-microservices/Microservices%20Capabilities/_build?definitionId=8 | http://mwasonarqube.eastus2.cloudapp.azure.com/dashboard?id=build%3Ahelix-itsm-microservice | . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#itsm-cicd",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#itsm-cicd"
  },"60": {
    "doc": "CICD Pipelines",
    "title": "Build Pipeline:",
    "content": "For the latest version you can find in here https://github.dxc.com/MWA/ms-itsm/blob/develop/azure-pipelines.yml . # Starter pipeline # Start with a minimal pipeline that you can customize to build and deploy your code. # Add steps that build, run tests, deploy, and more: # https://aka.ms/yaml trigger: - master - develop - release/* pool: vmImage: 'ubuntu-20.04' stages: - stage: Build displayName: Build application jobs: - job: Build displayName: Nodejs Build steps: - task: Npm@1 displayName: npm install inputs: command: 'install' workingDir: 'azure/function' - stage: Code_Quality displayName: Scan Code Quality condition: and(succeeded(), ne(variables['Build.Reason'], 'PullRequest')) jobs: - job: Sonar displayName: Sonar steps: - task: SonarQubePrepare@4 inputs: SonarQube: 'mwasonarqube' scannerMode: 'CLI' configMode: 'manual' cliProjectKey: 'build:helix-itsm-microservice' cliProjectName: 'build:helix-itsm-microservice' cliProjectVersion: '$(Build.SourceBranchName)' cliSources: '.' extraProperties: | # Additional properties that will be passed to the scanner, # Put one key=value per line, example: # sonar.exclusions=**/*.bin sonar.coverage.exclusions = \"**/server.js\" - task: SonarQubeAnalyze@4 - task: SonarQubePublish@4 inputs: pollingTimeoutSec: '300' - stage: Vulnerability displayName: Scan vulnerability application jobs: - job: Npm_Vulnerability displayName: Npm Vulnerability steps: - task: Npm@1 displayName: npm install inputs: command: 'install' workingDir: 'azure/function' - task: CmdLine@2 displayName: npm audit inputs: script: | sudo npm install -g retire --unsafe-perm=true --allow-root sudo npm install -g npm-audit-html --unsafe-perm=true --allow-root npm audit --json | npm-audit-html ls workingDirectory: 'azure/function' - task: CopyFiles@2 displayName: 'Copy Files to: Copy Vulnerability Report' inputs: SourceFolder: './azure/function' Contents: | npm-audit.html !node_modules/** TargetFolder: '$(Build.ArtifactStagingDirectory)' OverWrite: true - task: PublishBuildArtifacts@1 inputs: PathtoPublish: '$(Build.ArtifactStagingDirectory)' ArtifactName: 'vulnerability-report' publishLocation: 'Container' - stage: Publish displayName: Publish Artifacts jobs: - job: publish displayName: Publish steps: - task: CopyFiles@2 displayName: 'Copy Files to: Staging Artifact' inputs: SourceFolder: ./azure TargetFolder: '$(Build.ArtifactStagingDirectory)' OverWrite: true - task: PublishBuildArtifacts@1 inputs: PathtoPublish: '$(Build.ArtifactStagingDirectory)' ArtifactName: 'helix-itsm-microservice' publishLocation: 'Container' . Terraform Template . The latest version you can find in here https://github.dxc.com/MWA/provision/blob/master/usecase/helix/main.tf . resource \"azurerm_resource_group\" \"itsm_beg\" { name = \"${var.customer_name}-backend\" location = \"${var.location }\" } resource \"azurerm_function_app\" \"itsm_beg\" { name = \"${var.customer_name}-itsm-microservice\" location = azurerm_resource_group.itsm_beg.location resource_group_name = azurerm_resource_group.itsm_beg.name app_service_plan_id = azurerm_app_service_plan.srg.id storage_account_name = azurerm_storage_account.srg.name storage_account_access_key = azurerm_storage_account.srg.primary_access_key os_type = \"linux\" https_only = true site_config { always_on = true linux_fx_version = \"DOCKER|${var.itsm_image}\" } app_settings = { DOCKER_REGISTRY_SERVER_PASSWORD = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.DOCKER_REGISTRY_SERVER_PASSWORD.versionless_id}/${azurerm_key_vault_secret.DOCKER_REGISTRY_SERVER_PASSWORD.version})\" DOCKER_REGISTRY_SERVER_URL = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.DOCKER_REGISTRY_SERVER_URL.versionless_id}/${azurerm_key_vault_secret.DOCKER_REGISTRY_SERVER_URL.version})\" DOCKER_REGISTRY_SERVER_USERNAME = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.DOCKER_REGISTRY_SERVER_USERNAME.versionless_id}/${azurerm_key_vault_secret.DOCKER_REGISTRY_SERVER_USERNAME.version})\" APPINSIGHTS_INSTRUMENTATIONKEY = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.APPINSIGHTS_INSTRUMENTATIONKEY.versionless_id}/${azurerm_key_vault_secret.APPINSIGHTS_INSTRUMENTATIONKEY.version})\" APPLICATIONINSIGHTS_CONNECTION_STRING = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.APPLICATIONINSIGHTS_CONNECTION_STRING.versionless_id}/${azurerm_key_vault_secret.APPLICATIONINSIGHTS_CONNECTION_STRING.version})\" ITSM_SERVICENOW = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.ITSM_SERVICENOW.versionless_id}/${azurerm_key_vault_secret.ITSM_SERVICENOW.version})\" DB_API = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.DB_API.versionless_id}/${azurerm_key_vault_secret.DB_API.version})\" REDISCACHEHOSTNAME = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.REDISCACHEHOSTNAME.versionless_id}/${azurerm_key_vault_secret.REDISCACHEHOSTNAME.version})\" REDISCACHEKEY = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.REDISCACHEKEY.versionless_id}/${azurerm_key_vault_secret.REDISCACHEKEY.version})\" AZURE_STORAGE = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.AZURE_STORAGE.versionless_id}/${azurerm_key_vault_secret.AZURE_STORAGE.version})\" WEBSITE_ENABLE_SYNC_UPDATE_SITE = true WEBSITES_ENABLE_APP_SERVICE_STORAGE = false } } . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#build-pipeline-1",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#build-pipeline-1"
  },"61": {
    "doc": "CICD Pipelines",
    "title": "ITSM-Servicenow CI/CD",
    "content": "Prerequisites . | Azure Service Principle Key has Owner Permission on Subscription | Has Access Rights to access Azure DevOps | https://dev.azure.com/mwa-microservices/Microservices%20Capabilities Source Code and Build . | https://github.dxc.com/MWA/ms-itsm-servicenow | https://dev.azure.com/mwa-microservices/Microservices%20Capabilities/_build?definitionId=9 | http://mwasonarqube.eastus2.cloudapp.azure.com/dashboard?id=build%3Ahelix-itsm-servicenow-microservice | . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#itsm-servicenow-cicd",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#itsm-servicenow-cicd"
  },"62": {
    "doc": "CICD Pipelines",
    "title": "Build Pipeline:",
    "content": "For the latest version you can find in here https://github.dxc.com/MWA/ms-itsm-servicenow/blob/develop/azure-pipelines.yml . # Starter pipeline # Start with a minimal pipeline that you can customize to build and deploy your code. # Add steps that build, run tests, deploy, and more: # https://aka.ms/yaml trigger: - master - develop - feature/* - release/* pool: vmImage: 'ubuntu-20.04' stages: - stage: Build displayName: Build application jobs: - job: Build displayName: Nodejs Build steps: - task: Npm@1 displayName: npm install inputs: command: 'install' workingDir: 'azure/function' - stage: Code_Quality displayName: Scan Code Quality condition: and(succeeded(), ne(variables['Build.Reason'], 'PullRequest')) jobs: - job: Sonar displayName: Sonar steps: - task: SonarQubePrepare@4 inputs: SonarQube: 'mwasonarqube' scannerMode: 'CLI' configMode: 'manual' cliProjectKey: 'build:helix-itsm-servicenow-microservice' cliProjectName: 'build:helix-itsm-servicenow-microservice' cliProjectVersion: '$(Build.SourceBranchName)' cliSources: '.' extraProperties: | # Additional properties that will be passed to the scanner, # Put one key=value per line, example: # sonar.exclusions=**/*.bin sonar.coverage.exclusions = \"**/server.js\" - task: SonarQubeAnalyze@4 - task: SonarQubePublish@4 inputs: pollingTimeoutSec: '300' - stage: Vulnerability displayName: Scan vulnerability application jobs: - job: Npm_Vulnerability displayName: Npm Vulnerability steps: - task: Npm@1 displayName: npm install inputs: command: 'install' workingDir: 'azure/function' - task: CmdLine@2 displayName: npm audit inputs: script: | sudo npm install -g retire --unsafe-perm=true --allow-root sudo npm install -g npm-audit-html --unsafe-perm=true --allow-root npm audit --json | npm-audit-html ls workingDirectory: 'azure/function' - task: CopyFiles@2 displayName: 'Copy Files to: Copy Vulnerability Report' inputs: SourceFolder: './azure/function' Contents: | npm-audit.html !node_modules/** TargetFolder: '$(Build.ArtifactStagingDirectory)' OverWrite: true - task: PublishBuildArtifacts@1 inputs: PathtoPublish: '$(Build.ArtifactStagingDirectory)' ArtifactName: 'vulnerability-report' publishLocation: 'Container' - stage: Publish displayName: Publish Artifacts jobs: - job: publish displayName: Publish steps: - task: CopyFiles@2 displayName: 'Copy Files to: Staging Artifact' inputs: SourceFolder: ./azure TargetFolder: '$(Build.ArtifactStagingDirectory)' OverWrite: true - task: PublishBuildArtifacts@1 inputs: PathtoPublish: '$(Build.ArtifactStagingDirectory)' ArtifactName: 'helix-itsm-servicenow-microservice' publishLocation: 'Container' . Terraform Template . The latest version you can find in here https://github.dxc.com/MWA/provision/blob/master/usecase/helix/main.tf . resource \"azurerm_resource_group\" \"itsm_servicenow_beg\" { name = \"${var.customer_name}-backend\" location = \"${var.location }\" } resource \"azurerm_function_app\" \"itsm_servicenow_beg\" { name = \"${var.customer_name}-itsm-servicenow-microservice\" location = azurerm_resource_group.itsm_servicenow_beg.location resource_group_name = azurerm_resource_group.itsm_servicenow_beg.name app_service_plan_id = azurerm_app_service_plan.srg.id storage_account_name = azurerm_storage_account.srg.name storage_account_access_key = azurerm_storage_account.srg.primary_access_key os_type = \"linux\" https_only = true version = \"~3\" identity { type = \"SystemAssigned\" } site_config { always_on = true linux_fx_version = \"DOCKER|${var.itsm_servicenow_image}\" } app_settings = { DOCKER_REGISTRY_SERVER_PASSWORD = \"${var.DOCKER_REGISTRY_SERVER_PASSWORD}\" DOCKER_REGISTRY_SERVER_URL = \"${var.DOCKER_REGISTRY_SERVER_URL}\" DOCKER_REGISTRY_SERVER_USERNAME = \"${var.DOCKER_REGISTRY_SERVER_USERNAME}\" APPINSIGHTS_INSTRUMENTATIONKEY = azurerm_application_insights.srg.instrumentation_key APPLICATIONINSIGHTS_CONNECTION_STRING = azurerm_application_insights.srg.connection_string SNOW_URL = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.SNOW_URL.versionless_id}/${azurerm_key_vault_secret.SNOW_URL.version})\" SNOW_USER = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.SNOW_USER.versionless_id}/${azurerm_key_vault_secret.SNOW_USER.version})\" SNOW_PW = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.SNOW_PW.versionless_id}/${azurerm_key_vault_secret.SNOW_PW.version})\" CONNECTNOW_INBOUND = \"api/mpsc/connectnow/inbound\" PDXC_INTEGRATION = true KB_BASE_IDS = \"${var.KB_BASE_IDS}\" FE_KB_URL_TEMPLATE = \"https://${var.customer_name}-frontend.azurefd.net/knowledges/detail/{KB_NUMBER}\" PDXC_API = \"${var.PDXC_API}\" KB_CONTENT_TEXT_LIMIT = \"200\" PDXC_API_TABLE_URL = \"{\\\"INCIDENT\\\":\\\"inc1-dev\\\",\\\"REQUEST\\\":\\\"req1-dev\\\"}\" KB_ANNOUCEMENT_ENCODED_QUERY = \"${var.KB_ANNOUCEMENT_ENCODED_QUERY}\" KB_TOP_ENCODED_QUERY = \"${var.KB_TOP_ENCODED_QUERY}\" KB_FEATURED_ENCODED_QUERY = \"${var.KB_FEATURED_ENCODED_QUERY}\" KB_ANNOUCEMENT_CONDITION = \"${var.KB_ANNOUCEMENT_CONDITION}\" WEBSITE_ENABLE_SYNC_UPDATE_SITE = true WEBSITES_ENABLE_APP_SERVICE_STORAGE = false } } . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#build-pipeline-2",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#build-pipeline-2"
  },"63": {
    "doc": "CICD Pipelines",
    "title": "App-database CI/CD",
    "content": "Prerequisites . | Azure Service Principle Key has Owner Permission on Subscription | Has Access Rights to access Azure DevOps | https://dev.azure.com/mwa-microservices/Microservices%20Capabilities Source Code and Build . | https://github.dxc.com/MWA/ms-app-database | https://dev.azure.com/mwa-microservices/Microservices%20Capabilities/_build?definitionId=10 ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#app-database-cicd",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#app-database-cicd"
  },"64": {
    "doc": "CICD Pipelines",
    "title": "Build Pipeline:",
    "content": "For the latest version you can find in here https://github.dxc.com/MWA/ms-app-database/blob/develop/azure-pipelines.yml ```yaml resource “azurerm_resource_group” “cosmos_app_database_beg” { name = “${var.customer_name}-backend” location = “${var.location }” } . | . resource “azurerm_function_app” “cosmos_app_database_beg” { name = “${var.customer_name}-app-database-microservice” location = azurerm_resource_group.cosmos_app_database_beg.location resource_group_name = azurerm_resource_group.cosmos_app_database_beg.name app_service_plan_id = azurerm_app_service_plan.srg.id storage_account_name = azurerm_storage_account.srg.name storage_account_access_key = azurerm_storage_account.srg.primary_access_key os_type = “linux” https_only = true version = “~3” identity { type = “SystemAssigned” } site_config { always_on = true linux_fx_version = “DOCKER|${var.app_database_image}” } app_settings = { DOCKER_REGISTRY_SERVER_PASSWORD = “${var.DOCKER_REGISTRY_SERVER_PASSWORD}” DOCKER_REGISTRY_SERVER_URL = “${var.DOCKER_REGISTRY_SERVER_URL}” DOCKER_REGISTRY_SERVER_USERNAME = “${var.DOCKER_REGISTRY_SERVER_USERNAME}” APPINSIGHTS_INSTRUMENTATIONKEY = azurerm_application_insights.srg.instrumentation_key APPLICATIONINSIGHTS_CONNECTION_STRING = azurerm_application_insights.srg.connection_string HOST = “@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.HOST.versionless_id}/${azurerm_key_vault_secret.HOST.version})” AUTH_KEY = “@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.AUTH_KEY.versionless_id}/${azurerm_key_vault_secret.AUTH_KEY.version})” DATABASE_ID = “@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.DATABASE_ID.versionless_id}/${azurerm_key_vault_secret.DATABASE_ID.version})” DATABASE_CONNECTION = “@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.DATABASE_CONNECTION.versionless_id}/${azurerm_key_vault_secret.DATABASE_CONNECTION.version})” ITSM_SERVICES_API = “@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.ITSM_SERVICES_API.versionless_id}/${azurerm_key_vault_secret.ITSM_SERVICES_API.version})” WEBSITE_ENABLE_SYNC_UPDATE_SITE = true WEBSITES_ENABLE_APP_SERVICE_STORAGE = false } } . ## Notification CI/CD ### Prerequisites - Azure Service Principle Key has Owner Permission on Subscription - Has Access Rights to access Azure DevOps - https://dev.azure.com/mwa-microservices/Microservices%20Capabilities ### Source Code and Build - https://github.dxc.com/MWA/ms-notification - https://dev.azure.com/mwa-microservices/Microservices%20Capabilities/_build?definitionId=12 ## Build Pipeline: For the latest version you can find in here https://github.dxc.com/MWA/ms-notification/blob/develop/azure-pipelines.yml ```yaml resource \"azurerm_resource_group\" \"notification_beg\" { name = \"${var.customer_name}-backend\" location = \"${var.location }\" } resource \"azurerm_function_app\" \"notification_beg\" { name = \"${var.customer_name}-notification-microservice\" location = azurerm_resource_group.notification_beg.location resource_group_name = azurerm_resource_group.notification_beg.name app_service_plan_id = azurerm_app_service_plan.srg.id storage_account_name = azurerm_storage_account.srg.name storage_account_access_key = azurerm_storage_account.srg.primary_access_key os_type = \"linux\" https_only = true version = \"~3\" identity { type = \"SystemAssigned\" } site_config { always_on = true linux_fx_version = \"DOCKER|${var.notification_image}\" } app_settings = { DOCKER_REGISTRY_SERVER_PASSWORD = \"${var.DOCKER_REGISTRY_SERVER_PASSWORD}\" DOCKER_REGISTRY_SERVER_URL = \"${var.DOCKER_REGISTRY_SERVER_URL}\" DOCKER_REGISTRY_SERVER_USERNAME = \"${var.DOCKER_REGISTRY_SERVER_USERNAME}\" APPINSIGHTS_INSTRUMENTATIONKEY = azurerm_application_insights.srg.instrumentation_key APPLICATIONINSIGHTS_CONNECTION_STRING = azurerm_application_insights.srg.connection_string DB_API = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.DB_API.versionless_id}/${azurerm_key_vault_secret.DB_API.version})\" FIREBASE_ADMIN_AUTH = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.FIREBASE_ADMIN_AUTH.versionless_id}/${azurerm_key_vault_secret.FIREBASE_ADMIN_AUTH.version})\" FIREBASE_ADMIN_ENDPOINT = \"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.FIREBASE_ADMIN_ENDPOINT.versionless_id}/${azurerm_key_vault_secret.FIREBASE_ADMIN_ENDPOINT.version})\" AZURE_SERVICEBUS_CONNECTIONSTRING =\"@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.AZURE_SERVICEBUS_CONNECTIONSTRING.versionless_id}/${azurerm_key_vault_secret.AZURE_SERVICEBUS_CONNECTIONSTRING.version})\" WEBPUSH_TOPIC = \"${var.customer_name}-topic\" WEBPUSH_SUBSCRIPTION = \"notification\" WEBSITE_ENABLE_SYNC_UPDATE_SITE = true WEBSITES_ENABLE_APP_SERVICE_STORAGE = false } } . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#build-pipeline-3",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#build-pipeline-3"
  },"65": {
    "doc": "CICD Pipelines",
    "title": "Azure API Magement",
    "content": "For each of microservices we will publish api to API management by using the swagger . | https://github.dxc.com/MWA/ms-app-database/blob/develop/azure/apim/swagger.json | https://github.dxc.com/MWA/ms-itsm/blob/develop/azure/apim/swagger.json | https://github.dxc.com/MWA/ms-itsm-servicenow/blob/develop/azure/apim/swagger.json | . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#azure-api-magement",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#azure-api-magement"
  },"66": {
    "doc": "CICD Pipelines",
    "title": "Azure KeyVault",
    "content": "Azure Key Vault is a cloud service for securely storing and accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, certificates, or cryptographic keys. Key Vault service supports two types of containers: vaults and managed hardware security module(HSM) pools. Vaults support storing software and HSM-backed keys, secrets, and certificates. Managed HSM pools only support HSM-backed keys. To do any operations with Key Vault, you first need to authenticate to it. There are three ways to authenticate to Key Vault: . | Managed identities for Azure resources: When you deploy an app on a virtual machine in Azure, you can assign an identity to your virtual machine that has access to Key Vault. You can also assign identities to other Azure resources. The benefit of this approach is that the app or service isn’t managing the rotation of the first secret. Azure automatically rotates the identity. We recommend this approach as a best practice. | Service principal and certificate: You can use a service principal and an associated certificate that has access to Key Vault. We don’t recommend this approach because the application owner or developer must rotate the certificate. | Service principal and secret: Although you can use a service principal and a secret to authenticate to Key Vault, we don’t recommend it. It’s hard to automatically rotate the bootstrap secret that’s used to authenticate to Key Vault. | . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#azure-keyvault",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#azure-keyvault"
  },"67": {
    "doc": "CICD Pipelines",
    "title": "Azure security baseline for Key Vault",
    "content": "https://docs.microsoft.com/en-us/security/benchmark/azure/baselines/key-vault-security-baseline . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#azure-security-baseline-for-key-vault",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#azure-security-baseline-for-key-vault"
  },"68": {
    "doc": "CICD Pipelines",
    "title": "Add new key vault secret using Terraform",
    "content": "resource \"azurerm_key_vault_secret\" \"example\" { name = \"secret-sauce\" value = \"szechuan\" key_vault_id = azurerm_key_vault.example.id } . https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/key_vault_secret . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#add-new-key-vault-secret-using-terraform",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#add-new-key-vault-secret-using-terraform"
  },"69": {
    "doc": "CICD Pipelines",
    "title": "Custom Configuration For KeyVault",
    "content": "https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/key_vault . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#custom-configuration-for-keyvault",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#custom-configuration-for-keyvault"
  },"70": {
    "doc": "CICD Pipelines",
    "title": "Current Keyvault",
    "content": "resource \"azurerm_redis_cache\" \"redis\" { name = \"${var.customer_name}-redis-cache\" location = azurerm_resource_group.srg.location resource_group_name = azurerm_resource_group.srg.name capacity = 0 family = \"C\" sku_name = \"Basic\" enable_non_ssl_port = false minimum_tls_version = \"1.2\" redis_configuration { } } resource \"azurerm_cdn_profile\" \"cdn\" { name = \"${var.cdn_name}\" location = azurerm_resource_group.srg.location resource_group_name = azurerm_resource_group.srg.name sku = \"Standard_Akamai\" } resource \"azurerm_cdn_endpoint\" \"cdn\" { name = \"${var.cdn_name}\" profile_name = azurerm_cdn_profile.cdn.name location = azurerm_resource_group.srg.location resource_group_name = azurerm_resource_group.srg.name origin { name = \"${var.cdn_name}\" host_name = \"${azurerm_storage_account.srg.name}.blob.core.windows.net\" } origin_host_header = \"${azurerm_storage_account.srg.name}.blob.core.windows.net\" } resource \"azurerm_cdn_endpoint\" \"frontend\" { name = \"${var.customer_name}-frontend\" profile_name = azurerm_cdn_profile.cdn.name location = azurerm_resource_group.srg.location resource_group_name = azurerm_resource_group.srg.name origin { name = \"${var.customer_name}-frontend\" host_name = \"${var.customer_name}-frontend.azurefd.net\" } origin_host_header = \"${var.customer_name}-frontend.azurefd.net\" } //key vault data \"azurerm_client_config\" \"current\" {} resource \"azurerm_key_vault\" \"srg\" { name = \"${var.keyvault_name}\" location = azurerm_resource_group.srg.location resource_group_name = azurerm_resource_group.srg.name enabled_for_disk_encryption = true tenant_id = data.azurerm_client_config.current.tenant_id purge_protection_enabled = false soft_delete_retention_days = 7 sku_name = \"standard\" access_policy { tenant_id = data.azurerm_client_config.current.tenant_id object_id = data.azurerm_client_config.current.object_id secret_permissions = [ \"Get\", \"Set\", \"List\", \"Delete\" ] storage_permissions = [ \"Get\", ] } } //shared resource keyvault resource \"azurerm_key_vault_secret\" \"DOCKER_REGISTRY_SERVER_PASSWORD\" { name = \"DOCKER-REGISTRY-SERVER-PASSWORD\" value = \"${var.DOCKER_REGISTRY_SERVER_PASSWORD}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"DOCKER_REGISTRY_SERVER_URL\" { name = \"DOCKER-REGISTRY-SERVER-URL\" value = \"${var.DOCKER_REGISTRY_SERVER_URL}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"DOCKER_REGISTRY_SERVER_USERNAME\" { name = \"DOCKER-REGISTRY-SERVER-USERNAME\" value = \"${var.DOCKER_REGISTRY_SERVER_USERNAME}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"APPINSIGHTS_INSTRUMENTATIONKEY\" { name = \"APPINSIGHTS-INSTRUMENTATIONKEY\" value = azurerm_application_insights.srg.instrumentation_key key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"APPLICATIONINSIGHTS_CONNECTION_STRING\" { name = \"APPLICATIONINSIGHTS-CONNECTION-STRING\" value = azurerm_application_insights.srg.connection_string key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"AzureWebJobsStorage\" { name = \"AzureWebJobsStorage\" value = azurerm_storage_account.srg.primary_connection_string key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"Subscription_Key\" { name = \"SubscriptionKey\" value = azurerm_api_management_subscription.subscription.primary_key key_vault_id = azurerm_key_vault.srg.id } //itsm servicenow keyvault resource \"azurerm_key_vault_secret\" \"CONNECTNOW_INBOUND\" { name = \"CONNECTNOW-INBOUND\" value = \"api/mpsc/connectnow/inbound\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"PDXC_INTEGRATION\" { name = \"PDXC-INTEGRATION\" value = \"true\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"KB_BASE_IDS\" { name = \"KB-BASE-IDS\" value = \"${var.KB_BASE_IDS}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"FE_KB_URL_TEMPLATE\" { name = \"FE-KB-URL-TEMPLATE\" value = \"https://${var.customer_name}-frontend.azurefd.net/knowledges/detail/{KB_NUMBER}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"PDXC_API\" { name = \"PDXC-API\" value = \"${var.PDXC_API}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"KB_CONTENT_TEXT_LIMIT\" { name = \"KB-CONTENT-TEXT-LIMIT\" value = \"200\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"PDXC_API_TABLE_URL\" { name = \"PDXC-API-TABLE-URL\" value = \"{\\\"INCIDENT\\\":\\\"inc1-dev\\\",\\\"REQUEST\\\":\\\"req1-dev\\\"}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"KB_ANNOUCEMENT_ENCODED_QUERY\" { name = \"KB-ANNOUCEMENT-ENCODED-QUERY\" value = \"${var.KB_ANNOUCEMENT_ENCODED_QUERY}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"KB_TOP_ENCODED_QUERY\" { name = \"KB-TOP-ENCODED-QUERY\" value = \"${var.KB_TOP_ENCODED_QUERY}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"KB_FEATURED_ENCODED_QUERY\" { name = \"KB-FEATURED-ENCODED-QUERY\" value = \"${var.KB_FEATURED_ENCODED_QUERY}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"SNOW_URL\" { name = \"ITSM-SNOW-URL\" value = \"${var.SNOW_URL}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"SNOW_PW\" { name = \"ITSM-SNOW-PW\" value = \"${var.SNOW_PW}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"SNOW_USER\" { name = \"ITSM-SNOW-USER\" value = \"${var.SNOW_USER}\" key_vault_id = azurerm_key_vault.srg.id } //app-database resource \"azurerm_key_vault_secret\" \"HOST\" { name = \"HOST\" value = azurerm_cosmosdb_account.db.endpoint key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"AUTH_KEY\" { name = \"AUTH-KEY\" value = azurerm_cosmosdb_account.db.primary_key key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"DATABASE_ID\" { name = \"DATABASE-ID\" value = \"helix-app\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"DATABASE_CONNECTION\" { name = \"DATABASE-CONNECTION\" value = azurerm_cosmosdb_account.db.connection_strings[0] key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"ITSM_SERVICES_API\" { name = \"ITSM-SERVICES-API\" value = \"{\\\"url\\\": \\\"https://${var.customer_name}-apim.azurefd.net/${var.customer_name}-itsm-microservice/api\\\", \\\"header_key\\\":\\\"ocp-apim-subscription-key\\\", \\\"header_value\\\": \\\"${azurerm_api_management_subscription.subscription.primary_key}\\\"}\" key_vault_id = azurerm_key_vault.srg.id } //itsm resource \"azurerm_key_vault_secret\" \"ITSM_SERVICENOW\" { name = \"ITSM-SERVICENOW\" value = \"{\\\"url\\\": \\\"https://${var.customer_name}-apim.azurefd.net/${var.customer_name}-itsm-servicenow-microservice\\\", \\\"header_key\\\":\\\"ocp-apim-subscription-key\\\", \\\"header_value\\\": \\\"${azurerm_api_management_subscription.subscription.primary_key}\\\"}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"DB_API\" { name = \"DB-API\" value = \"{\\\"url\\\": \\\"https://${var.customer_name}-apim.azurefd.net/${var.customer_name}-app-database-microservice\\\",\\\"key\\\": \\\"${azurerm_api_management_subscription.subscription.primary_key}\\\"}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"REDISCACHEHOSTNAME\" { name = \"REDISCACHEHOSTNAME\" value = azurerm_redis_cache.redis.hostname key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"REDISCACHEKEY\" { name = \"REDISCACHEKEY\" value = azurerm_redis_cache.redis.primary_access_key key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"AZURE_STORAGE\" { name = \"AZURE-STORAGE\" value = \"{\\\"connection_string\\\":\\\"${azurerm_storage_account.srg.primary_connection_string}\\\",\\\"container_image\\\":\\\"kb-attachment\\\",\\\"cdn_url\\\":\\\"https://${var.customer_name}-cdn.azureedge.net/\\\"}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"FIREBASE_ADMIN_AUTH\" { name = \"FIREBASE-ADMIN-AUTH\" value = \"${var.FIREBASE_ADMIN_AUTH}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"FIREBASE_ADMIN_ENDPOINT\" { name = \"FIREBASE-ADMIN-ENDPOINT\" value = \"${var.FIREBASE_ADMIN_ENDPOINT}\" key_vault_id = azurerm_key_vault.srg.id } resource \"azurerm_key_vault_secret\" \"AZURE_SERVICEBUS_CONNECTIONSTRING\" { name = \"AZURE-SERVICEBUS-CONNECTIONSTRING\" value = azurerm_servicebus_namespace.servicebus.default_primary_connection_string key_vault_id = azurerm_key_vault.srg.id } //service bus resource \"azurerm_servicebus_namespace\" \"servicebus\" { name = \"${var.customer_name}-servicebus-namespace\" location = azurerm_resource_group.srg.location resource_group_name = azurerm_resource_group.srg.name sku = \"Standard\" tags = { source = \"terraform\" } } resource \"azurerm_servicebus_topic\" \"topic\" { name = \"${var.customer_name}-topic\" resource_group_name = azurerm_resource_group.srg.name namespace_name = azurerm_servicebus_namespace.servicebus.name enable_partitioning = true } resource \"azurerm_servicebus_subscription\" \"subscription\" { name = \"notification\" resource_group_name = azurerm_resource_group.srg.name namespace_name = azurerm_servicebus_namespace.servicebus.name topic_name = azurerm_servicebus_topic.topic.name max_delivery_count = 1 } . ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html#current-keyvault",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html#current-keyvault"
  },"71": {
    "doc": "CICD Pipelines",
    "title": "CICD Pipelines",
    "content": " ",
    "url": "/docs/Build-Kit/CICD%20Pipelines.html",
    "relUrl": "/docs/Build-Kit/CICD%20Pipelines.html"
  },"72": {
    "doc": "Data Protection Impact Assessment (DPIA)",
    "title": "Data Protection Impact Assessment (DPIA)",
    "content": "The Data Protection Impact Assessment (DPIA) can be found here. ",
    "url": "/docs/Build-Kit/Data%20Protection%20Impact%20Assessment%20(DPIA).html",
    "relUrl": "/docs/Build-Kit/Data%20Protection%20Impact%20Assessment%20(DPIA).html"
  },"73": {
    "doc": "Definition of Terms",
    "title": "Definition of Terms",
    "content": "| Terms/Acronyms | Definition | Description | . | AAD | Azure Active Directory |   | . | API | Application Programming interface |   | . | ASD | Agile Service Desk |   | . | AWS | Amazon Web Services |   | . | Azure Front Door |   | Azure cloud-based secure entry point providing access to the Azure-based web site. | . | CI/CD | Continuous Integration/ Continuous Deployment | An automated build, test and deploy method that ensures quick and seamless code delivery. | . | Change Management |   | Process by which enhancements, features or designs are added, removed or significantly altered. | . | CLI | Command Line Interface | Mostly used in development, configurations or automations in running most services. Instructing the system/software using the CLI | . | CMO | Current Method of Operation | The processes, architecture, resources, etc, of a service at the beginning of a business transformation. See also Future Method of Operation (FMO). | . | FMO | Future Method of Operation | The desired end state of processes, architecture, resources, etc, of a service. Usually compared to Current Method of Operation (CMO) at the beginning of a business transformation. | . | HA | High Availability |   | . | IaaS | Infrastructure as a Service | Use to deploy Uptime, where Boomi, front-end codes, back-end codes, provisions (required/used services) are deployed | . | IdP | Identity Platform |   | . | Incident |   | Event that occurs that is not part of the standard operation of the Services as set out in this Solution Pack. | . | Integration |   | A connection to an external system acting as a service to another system. | . | IPaaS | Integration Platform as a Service | Use to obtain Uptime Integrations and Uptime workflows | . | ITTP | Integrated Transition &amp; Transformation Plan |   | . | JSON | javascript object notation | Use to input configure settings to import template/presets-like to another source with the same configuration requirements | . | KB | Knowledge Base | Searchable and viewable online library of electronic documents. | . | KPI | Key Performance Index | Metric providing a measure of quality of service. | . | L1 | Level 1 Support | First line of support, first end user point of contact with Service Desk. | . | L2 | Level 2 Support | Second-line technical support and troubleshooting. Escalation point for complex cases from L1. | . | L3 | Level 3 Support | Deep technical support and troubleshooting. Escalation point from L2 for highly critical and complex cases w/ business impact. | . | L4 | Level 4 Support | Expert-level troubleshooting. Vendor or Product Owner support. | . | Maintenance Window |   | The period of time used by DXC or Customer for maintenance activities as set out in this Solution Pack. Maintenance Windows may result in Services not being available. | . | MFA | Multi-Factor Authentication | Combines two or more independent credentials; what the user knows such as passwords, what the user has such as security token and what the user is using by using biometric verification methods | . | MID Server | Management, Instrumentation and Discovery Server | ServiceNow server that facilitates communication and data movement between a single ServiceNow instance and external applications, data sources, and services. | . | NFS | Network File System | Allowing a user on a client computer to access files over a computer network - used in AKS Boomi in 3 molecule node netapp | . | PAT | Personal Access Token | Github authentication workflow higher than password authentication, to instead use a random character to securely access repositories depending on the access granted from the Github profile, to either read/access/write, etc.. | . |   | Pipeline | An automated process that builds and deploys code into an environment. Implementation of CI/CD | . | POC | Point of Contact |   | . | Portal |   | Web user interface by which the User can interact with the supported services. Also, “UPtime Experience Gateway”. | . | R&amp;R | Roles &amp; Responsibilities | The definition and scope of a project’s participants and their respective duties. | . | RACI | Responsible Accountable Consulted Informed | Grid providing a global view of a project’s roles and responsibilities. | . | RBAC | Role-Based Access Control | Method of assigning system privileges based on the purpose of the account rather than individually-assigned rights. | . | Release |   | Initial roll out or bug fix updates to a product. | . | REST API | Representational State Transfer Application Programming Interface | A method for web apps to interact with services provided by another web-based service. | . | SAML | Security Assessment Markup Language |   | . | SLA | Service Level Agreement | Definition of service conditions, quality of service, expectations and responsibilities. | . | SME | Subject Matter Expert | Individual or team of individuals able to provide technical guidance for decisions in a particular field. | . | SOP/SOPs | Standard Operating Procedures | Collection of project technical documentation. | . |   | Terraform | A tool to implement Infrastructure as a Service (IaaS) allowing automation of build, change and version control for infrastructure. | . | SSO | Single Sign-On |   | . | TTM | Transition &amp; Transformation Methodology | Provides standard procedures, techniques, and templates into a single project management framework. | . | UEG | UPtime Experience Gateway | Web user interface by which the User can interact with the supported services. Also, “Portal”. | . | User |   | Human individual who is authorized by Customer to access the Services. | . | UAT | User Acceptance Test | Verification by a subset of Customer User base to ensure the product satisfies a predetermined success criteria. | . | Workflow |   | Series of steps required to complete a task such as X,or Y ordered in the proper sequence. | . | XM | eXperience Management | The process of measurement of every interaction people have with a company and identification of remediation opportunities. | . ",
    "url": "/docs/Definition-of-Terms",
    "relUrl": "/docs/Definition-of-Terms"
  },"74": {
    "doc": "Delivery Kit",
    "title": "Releases and Roadmap",
    "content": "Uptime can be implemented for existing client and for new logo solutions where DXC provides Digital Support &amp; Device Management Services. ",
    "url": "/docs/Delivery-kit/#releases-and-roadmap",
    "relUrl": "/docs/Delivery-kit/#releases-and-roadmap"
  },"75": {
    "doc": "Delivery Kit",
    "title": "Release 2 with features (current release)",
    "content": ". ( See solution guide for the previous and future release features ) . ",
    "url": "/docs/Delivery-kit/#release-2-with-features-current-release",
    "relUrl": "/docs/Delivery-kit/#release-2-with-features-current-release"
  },"76": {
    "doc": "Delivery Kit",
    "title": "Release Notes",
    "content": "Please refer to Release Notes. ",
    "url": "/docs/Delivery-kit/#release-notes",
    "relUrl": "/docs/Delivery-kit/#release-notes"
  },"77": {
    "doc": "Delivery Kit",
    "title": "Delivery Kit",
    "content": " ",
    "url": "/docs/Delivery-kit/",
    "relUrl": "/docs/Delivery-kit/"
  },"78": {
    "doc": "Build Kit",
    "title": "Uptime Design",
    "content": "This contains Diagrams, Deployment Patterns, Solutions, Logical Design, Hosting details, List of Components, Environments &amp; Endpoints, Initial Approaches, Guides, and FAQs: https://confluence.dxc.com/display/MWH/Uptime+Design . | Conceptual Design | Integration &amp; Workflow Design | ITSM Deployment Patterns | DXCi Deployment Patterns | Modern Workplace Solution Framework | Uptime Azure Architecture | UpTime Azure Boomi Hosting | Azure “Kit List” &amp; Estimate | UpTime Environments | Boomi Conceptual Design | Approach to Espressive | Approach to Qualtrics | Approach to 1e Tachyon | Uptime Integration Design | UpTime Notification Mapping | UpTime Logical Architecture | UpTime Microservices Designs | Uptime Portal API Design | PC Refresh Workflow | PC Return Standalone Workflow | PC Break Fix Workflow | Lost or Stolen PC Workflow | Acknowledge PC Workflow | PC Assignment Error Workflow | Boomi Customer Layout | UpTime Development Environments | UpTime Solution Guide | UpTime Solution FAQ | UpTime Sales Deck | UpTime Development Flow | . ",
    "url": "/docs/Build-Kit#uptime-design",
    "relUrl": "/docs/Build-Kit#uptime-design"
  },"79": {
    "doc": "Build Kit",
    "title": "Standard Deliverables",
    "content": "https://dxcportal.sharepoint.com/sites/dxcPLMCentral/SitePages/Standard%20Deliverables.aspx . ",
    "url": "/docs/Build-Kit#standard-deliverables",
    "relUrl": "/docs/Build-Kit#standard-deliverables"
  },"80": {
    "doc": "Build Kit",
    "title": "Standardized Offering Release Deliverables",
    "content": "DXC PLM has a standardized set of deliverables that are created for each release of an offering. These deliverables are grouped into kits based primarily on which orgainzations will u​se the deliverables. ​ . ",
    "url": "/docs/Build-Kit#standardized-offering-release-deliverables",
    "relUrl": "/docs/Build-Kit#standardized-offering-release-deliverables"
  },"81": {
    "doc": "Build Kit",
    "title": "Build Kit",
    "content": " ",
    "url": "/docs/Build-Kit",
    "relUrl": "/docs/Build-Kit"
  },"82": {
    "doc": "Home",
    "title": "Home",
    "content": "This is a bare-minimum template to create a Jekyll site that uses the Just the Docs theme. You can easily set the created site to be published on GitHub Pages – the README file explains how to do that, along with other details. If Jekyll is installed on your computer, you can also build and preview the created site locally. This lets you test changes before committing them, and avoids waiting for GitHub Pages.1 And you will be able to deploy your local build to a different platform than GitHub Pages. More specifically, the created site: . | uses a gem-based approach, i.e. uses a Gemfile and loads the just-the-docs gem | uses the GitHub Pages / Actions workflow to build and publish the site on GitHub Pages | . Other than that, you’re free to customize sites that you create with this template, however you like. You can easily change the versions of just-the-docs and Jekyll it uses, as well as adding further plugins. s Browse our documentation to learn more about how to use this theme. To get started with creating a site, just c23 “use this template”! And this is from outside the_site folder . | It can take up to 10 minutes for changes to your site to publish after you push the changes to GitHub. &#8617; . | . ",
    "url": "/",
    "relUrl": "/"
  }
}
